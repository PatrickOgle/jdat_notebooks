{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRSpec IFU Optimal Point Source Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _numpy_ for array math\n",
    "* _scipy_ for ndcube gaussian smoothing\n",
    "* _specutils_ for Spectrum1D data model and cube manipulation\n",
    "* _jdaviz_ : Cubeviz data visualization tool\n",
    "* _photutils_ to define circular apertures\n",
    "* _astropy.io_ for reading and writing FITS cubes and images\n",
    "* _astropy.wcs, units, coordinates_ for defining and reading WCS\n",
    "* _astropy.stats_ for sigma_clipping\n",
    "* _astropy.utils_ for downloading files from URLs\n",
    "* _matplotlib_ for plotting spectra and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize notebook to full width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import specutils\n",
    "from specutils import Spectrum1D, SpectralRegion\n",
    "from specutils.manipulation import extract_region, spectral_slab\n",
    "\n",
    "from jdaviz import CubeViz\n",
    "\n",
    "from photutils import CircularAperture, SkyCircularAperture, aperture_photometry\n",
    "from photutils.detection import DAOStarFinder\n",
    "\n",
    "from regions import PixCoord, CirclePixelRegion\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.utils.data import download_file\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install jwst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook illustrates various extraction methods for a point source in JWST NIRSpec IFU data. First we\n",
    "demonstrate a number of regular extraction techniques, including subset extraction with Cubeviz, simple sum over spaxels, cylindrical aperture, and conical aperture photometry. Then we compare optimal extraction using a WebbPSF model PSF to optimal extraction using a reference star PSF. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Simulated NIRSpec IFU Cube\n",
    "\n",
    "A faint (quasar) point source was simulated using the NIRSpec Instrument Performance Simulator (IPS), then run through the JWST Spec2 pipeline. We will use this for our science dataset.\n",
    "\n",
    "Read in the data both with fits.open (to inspect the data structure and header) and Spectrum1D.read to utilize specutils functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIRSpec IFU science data cube\n",
    "BoxPath = \"https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/IFU_optimal_extraction/\"\n",
    "fname = \"NRS00001-faintQSO-F100LP-G140H-01_1_491_SE_2020-08-25T12h15m00_s3d.fits\"\n",
    "filename = BoxPath + fname\n",
    "\n",
    "# Open and inspect the file with astropy.fits.open\n",
    "with fits.open(fname, memmap=False) as hdulist:\n",
    "    hdulist.info()\n",
    "    sci = hdulist['SCI'].data\n",
    "    err = hdulist['ERR'].data  \n",
    "    \n",
    "# Load original (untrimmed version) with Spectrum1D    \n",
    "spec1d_untrimmed = Spectrum1D.read(fname, format='JWST s3d')\n",
    "wavelength_untrimmed = spec1d_untrimmed.spectral_axis\n",
    "print()\n",
    "print(\"Wavelength: \", wavelength_untrimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Notes:* \n",
    "\n",
    "(1) Can we fix or suppress the AsdfWarning? It goes away if 'jwst' package is installed.\n",
    "\n",
    "(2) The default loader doesn't read in the uncertainty.\n",
    "\n",
    "(3) Unable to print the Spectrum1D object.\n",
    "\n",
    "(4) Spectrum1D 'JWST s3d' has trouble with the Box URL, but works with a local filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Science Data with Cubeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cubeviz = CubeViz()\n",
    "cubeviz.app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UI Instructions:\n",
    "* Load science datacube into Cubeviz using the next code cell below\n",
    "* Go to the Hammer-and-Screwdriver icon: Gear icon: Layer in the leftmost image viewer \n",
    "* In that tab, change the Linear stretch to 90 percentile to see the faint QSO target at (x,y) ~ (17, 21)\n",
    "* Scrubbing through the cube also helps to locate the source\n",
    "* Select a circular subset region centered on the source. \n",
    "* Note that the region is pixelated and doesn't include fractional pixels\n",
    "* Change the collapse method to \"Sum\" in spectrum viewer: Gear icon : Viewer \n",
    "* --This \"Sum\" method yields our subset extraction\n",
    "* Change the vertical zoom to see the spectral features in the Subset spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Notes*: \n",
    "\n",
    "(5) Image viewer contrast settings change when you click on the side bar to expand/contract jupyter scroll window\n",
    "\n",
    "(6) Spectrum viewer: Viewer cube collapse method should default to Sum (not Maximum)\n",
    "\n",
    "(7) Spectrum viewer y scale returns to autoscale when the region is moved, and y-zoom has to be adjusted again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cube into Cubeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data from local directory\n",
    "cubeviz.app.load_data(fname)\n",
    "\n",
    "# Data from url:\n",
    "#df = download_file(filename)\n",
    "#cubeviz.app.load_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:* \n",
    "\n",
    "(8) Spectral cube gives \"No spectral axis found\" warning for each extension of JWST NIRSpec IFU datacubes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Region from Cubeviz\n",
    "Export the region defined by the user in Cubeviz as an astropy CirclePixel Region, which has units of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubeviz_data = cubeviz.app.data_collection[0]\n",
    "try:\n",
    "    region1 = cubeviz.app.get_subsets_from_viewer('spectrum-viewer')['Subset 1']\n",
    "    print(region1)\n",
    "    region1_exists = True\n",
    "    center1_xy = [region1.center.x, region1.center.y]  \n",
    "    r_pix = region1.radius\n",
    "\n",
    "except Exception:\n",
    "    print(\"There are no regions selected in the cube viewer.\")\n",
    "    region1_exists = False\n",
    "    center1_xy = [17.1, 20.]\n",
    "    r_pix = 6.0\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:*\n",
    "\n",
    "(9) Resolve this glue core \"Future Warning\" about multidemensional indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Subset Spectrum in Cubeviz Spectrum Viewer\n",
    "Retrieve the spectrum (Subset1) of the user-defined region from the Spectrum Viewer as a Spectrum1D object. Trim to remove bad wavelength ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_region = SpectralRegion(1.0*u.um, 1.43*u.um)\n",
    "try:\n",
    "    spectrum_subset1_untrimmed = cubeviz.app.get_data_from_viewer('spectrum-viewer')['Subset 1']\n",
    "    print(spectrum_subset1_untrimmed)\n",
    "    \n",
    "    # Trim the extracted spectrum\n",
    "    spectrum_subset1 = extract_region(spectrum_subset1_untrimmed, trim_region)\n",
    "    \n",
    "    print()\n",
    "    print('Wavelength:', spectrum_subset1_untrimmed.spectral_axis)\n",
    "    print('Trimmed:', spectrum_subset1.spectral_axis)\n",
    "    print()\n",
    "\n",
    "except Exception:\n",
    "    print(\"There are no subsets selected in the spectrum viewer.\")\n",
    "    \n",
    "\n",
    "#spectrum_subset1_untrimmed = spectrum_subset1_untrimmed.with_spectral_unit(u.um)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Notes:* \n",
    "\n",
    "(10) Why does Spectrum1D.with_spectral_unit not work on the dataset from Subset 1?\n",
    "\n",
    "(11) Why does extract_region complain that \"No observer defined on WCS\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Spectrum by Sum Over Spaxels\n",
    "\n",
    "First trim the cube to remove bad edges and wavelengths. Perform a simple numpy sum over all spaxels in the cube as a rudimentary extraction method. Also sum over wavelength to collapse the cube.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the data cube and adjust region location\n",
    "wave_trim =[1.0*u.um,1.43*u.um]\n",
    "x_trim = [2,-1]\n",
    "y_trim = [5, -4]\n",
    "spec1d = spectral_slab(spec1d_untrimmed, wave_trim[0], wave_trim[1])[x_trim[0]:x_trim[1],y_trim[0]:y_trim[1],:]\n",
    "wavelength = spec1d.spectral_axis\n",
    "\n",
    "#Adjust region location in trimmed cube\n",
    "center1_trim = PixCoord(x=center1_xy[0]-x_trim[0], y=center1_xy[1]-y_trim[0])\n",
    "region1_trim = CirclePixelRegion(center=center1_trim, radius=r_pix)\n",
    "print(region1_trim)\n",
    "\n",
    "# Untrimmed vs. Trimmed cube dimensions \n",
    "print('')\n",
    "print('Untrimmed:')\n",
    "print('Shape:',np.shape(spec1d_untrimmed))\n",
    "print('Wavelength:', wavelength_untrimmed)\n",
    "print()\n",
    "print('Trimmed:')\n",
    "print('Shape:', np.shape(spec1d))\n",
    "print('Wavelength:', wavelength)\n",
    "\n",
    "# Sum over spaxels\n",
    "fnu_sum = np.sum(spec1d.flux, axis=(0, 1))\n",
    "print('Flux:', fnu_sum)\n",
    "\n",
    "#Sum over wavelength\n",
    "cube_sum = np.sum(spec1d.flux.value, axis=2)\n",
    "\n",
    "# Plots\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5)) \n",
    "ax1.plot(wavelength, fnu_sum)\n",
    "ax1.set_xlim(wavelength_untrimmed.value[0], wavelength_untrimmed.value[-1])\n",
    "ax1.set_title(\"Spaxel sums\")\n",
    "ax1.set_xlabel(\"Wavelength (um)\")  \n",
    "ax1.set_ylabel(\"SCA491 Flux Density\")\n",
    "\n",
    "ax2.imshow(np.transpose(cube_sum), norm=LogNorm())\n",
    "patch = region1.as_artist(facecolor='none', edgecolor='red', lw=2)\n",
    "patch = region1_trim.as_artist(facecolor='none', edgecolor='red', lw=2)\n",
    "ax2.add_patch(patch)\n",
    "ax2.set_title(\"Slice sums\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left: Sum over good spaxels.  Right: Sum over good wavelengths, with Cubeviz circular extraction region overplotted. Origin at upper left corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Notes:* \n",
    "\n",
    "(12) The cube (x,y) coordinates are transposed in the Spectrum1D object with respect to the astropy fits cube and the Cubeviz image display, so we have to transpose the image when displaying.\n",
    "\n",
    "(13) Would be nice to have specutils function(s) or Spectrum1D method(s) that do the equivalent of the Cubeviz collapse plugin, preserving the units and uncertainties, like this: cube_sum = spec1d.collapse(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Spectrum in Constant Radius Circular Aperture (Cylinder)\n",
    "This method is appropriate for an extended source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use photutils.aperture_photometry to measure flux in constant aperture\n",
    "aperture = CircularAperture((center1_trim.x,center1_trim.y),r=r_pix)\n",
    "print(aperture)\n",
    "spec1d_len = len(wavelength)\n",
    "cylinder_sum = []\n",
    "for idx in range(spec1d_len):\n",
    "    phot_table = aperture_photometry(spec1d.flux.value[:, :, idx], aperture)\n",
    "    cylinder_sum.append(phot_table['aperture_sum'][0])\n",
    "cylinder = Spectrum1D(flux=np.array(cylinder_sum)*u.MJy/u.sr, spectral_axis=spec1d.spectral_axis)\n",
    "print(cylinder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:*  Is there a way to retrieve the coordinates (RA, Dec) of the Subset1 region, for use in a SkyCircularAperture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Spectrum in Linearly Expanding Circular Aperture (Cone)\n",
    "This method is appropriate for a point source PSF with width proportional to wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use photutils.aperture_photometry to measure flux in expanding aperture\n",
    "cone_sum = []\n",
    "for idx in range(spec1d_len):\n",
    "    r_cone = r_pix * wavelength.value[idx]/ wavelength.value[0]\n",
    "    aperture_cone = CircularAperture((center1_trim.x,center1_trim.y), r=r_cone)\n",
    "    phot_table = aperture_photometry(spec1d.flux.value[:, :, idx], aperture_cone)\n",
    "    cone_sum.append(phot_table['aperture_sum'][0])\n",
    "    \n",
    "cone = Spectrum1D(flux=np.array(cone_sum)*u.MJy/u.sr, spectral_axis=spec1d.spectral_axis)\n",
    "print(cone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot and Compare Non-optimal Spectral Extractions\n",
    "Compare spectra extracted in cylinder, cone, Cubeviz subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrum_subset1)\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(15, 5)) \n",
    "\n",
    "ax1.set_title(\"Non-optimal spectral extractions\")\n",
    "ax1.set_xlabel(\"Observed Wavelength (microns)\")  \n",
    "ax1.set_ylabel(\"Flux Density\")\n",
    "ax1.set_xlim(0.99, 1.442)\n",
    "ax1.set_ylim(0, 0.6)\n",
    "\n",
    "print(cylinder.spectral_axis)\n",
    "ax1.plot(wavelength, cylinder.flux.value, label=\"Cylinder\", c='b')\n",
    "ax1.plot(wavelength, cone.flux.value, label=\"Cone\", c='darkorange', alpha=0.5)\n",
    "try:\n",
    "    ax1.plot(wavelength, spectrum_subset1.flux.value, c='r', label=\"Subset1\", alpha=0.4)\n",
    "except Exception:\n",
    "    print(\"There is no Cubeviz Subset1 spectrum to plot.\")\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the (non-optimal) cylindrical, conical, and Cubeviz subset spectral extractions. \n",
    "The conical extraction captures slightly more flux but is noisier than the other spectra at long wavelengths.\n",
    "Red-shifted Broad H-beta and narrow [O III] lines  are visible in the quasar spectra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebbPSF  Model PSF for Optimal Extraction\n",
    "Generate PSF model cube using WebbPSF for NIRSpec IFU, or read in precomputed PSF model cube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution! The WebbPSF model takes about 10 hr to run.  Uncomment the following cell to do so. Otherwise, read in the precomputed WebbPSF model, which covers the full F100LP/G140H wavelength range (blue and red). For other filter/grating combinations, uncomment and run the cell below using the wavelengths from the science data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#WebbPSF imports\n",
    "%pylab inline\n",
    "import webbpsf\n",
    "\n",
    "#WebbPSF commands used to create PSF model cube\n",
    "ns.image_mask = \"IFU\"  # Sets to 3x3 arcsec square mask\n",
    "ns = webbpsf.NIRSpec()\n",
    "wavelengths = wavelength*1.0E-6\n",
    "psfcube = ns.calc_datacube(wavelengths, fov_pixels=30, oversample=4,  add_distortion=True)\n",
    "psfcube.writeto(\"Webbpsf_ifucube.fits\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxPath = \"https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/IFU_optimal_extraction/\"\n",
    "psf_fname = \"Webbpsf_ifucube.fits\"\n",
    "psf_filename = BoxPath + psf_fname\n",
    "\n",
    "\n",
    "# Load with astropy.fits.open\n",
    "with fits.open(psf_fname, memmap=False) as hdulist:\n",
    "    psf_model = hdulist['DET_SAMP'].data\n",
    "    psf_hdr = hdulist['DET_SAMP'].header\n",
    "    hdulist.info()    \n",
    "\n",
    "#WebbPSF model wavelengths\n",
    "wave0_webbpsf = psf_hdr['WAVE0']*1.0E6\n",
    "dlam_webbpsf = (psf_hdr['WVLN0001']-psf_hdr['WVLN0000'])*1.0E6 #0.000235\n",
    "nwave_webbpsf = psf_hdr['NAXIS3']\n",
    "wavelength_webbpsf_untrimmed = np.array(wave0_webbpsf + np.arange(nwave_webbpsf) * dlam_webbpsf)\n",
    "\n",
    "#Trim wavelengths\n",
    "#Note that the trimmed wavelengths of the WebbPSF model are slightly different from the science data\n",
    "#Also need to extend them by 1 bin to match length of science data wavelength array\n",
    "good_webbpsf_wave = np.where((wavelength_webbpsf_untrimmed >= wave_trim[0].value) & (wavelength_webbpsf_untrimmed <= wave_trim[1].value))[0]\n",
    "good_webbpsf_wave = np.append(good_webbpsf_wave, good_webbpsf_wave[-1]+1) \n",
    "wavelength_webbpsf = wavelength_webbpsf_untrimmed[good_webbpsf_wave] * u.um\n",
    "print(\"Data Wavelength: \", wavelength)\n",
    "print(\"WebbPSF Wavelength\", wavelength_webbpsf)\n",
    "\n",
    "#Trim datacube\n",
    "psf_model=psf_model[good_webbpsf_wave[0]:good_webbpsf_wave[-1]+1,:,:]\n",
    "print(np.shape(psf_model))\n",
    "\n",
    "# Sum over wavelength\n",
    "psf_model_sum = np.sum(psf_model, axis=0)\n",
    "\n",
    "# Sum over spaxels\n",
    "psf_model_fnusum = np.sum(psf_model, axis=(1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:*  The file Webbpsf_ifucube.fits is large (946.3 MB) and takes some time to load from Box.\n",
    "It might behoove the user to download it to a local directory and retrieve it from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align Model PSF Cube with Science Data\n",
    "Window the simulated data. Flip, smooth, and shift the model PSF cube to align with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window the science data\n",
    "good_wave = np.where((wavelength_untrimmed >= wave_trim[0]) & (wavelength_untrimmed<=wave_trim[1]))[0]\n",
    "data_win = np.nan_to_num(np.array(sci)[good_wave[0]:good_wave[-1]+1, 5:-4, 3:])\n",
    "data_var = np.nan_to_num(np.array(err)[good_wave[0]:good_wave[-1]+1, 5:-4, 3:]) \n",
    "data_sum = np.sum(data_win, axis=0)\n",
    "print(np.shape(sci), np.shape(data_win), np.shape(data_var))\n",
    "\n",
    "# Flip model PSF left-right.  For some unknown reason, WebbPSF is flipped with respect to the IPS simulation.\n",
    "#psf_model_fliplr = psf_model\n",
    "psf_model_fliplr = psf_model[:, ::-1, :]\n",
    "\n",
    "# Smooth model to match data smoothing built into cube_build algorithm\n",
    "# EMSM smoothing for G140H grating\n",
    "scalerad = 0.046  # sigma (arcsec)\n",
    "pixelscale = 0.1\n",
    "scalerad_pix = scalerad / pixelscale\n",
    "psf_model_smoothed = scipy.ndimage.filters.gaussian_filter(psf_model_fliplr, (0.0, scalerad_pix, scalerad_pix), \n",
    "                                                           order=0, mode='reflect', cval=0.0, truncate=10.0)\n",
    "# Find location of star in collapsed data \n",
    "data_mean, data_median, data_std = sigma_clipped_stats(data_sum, sigma=3.0) \n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=5.*data_std)\n",
    "data_sources = daofind(data_sum-data_median) \n",
    "for col in data_sources.colnames:  \n",
    "    data_sources[col].info.format = '%.6g'  \n",
    "print(\"Sources detected in data:\")\n",
    "print(data_sources)  \n",
    "print()\n",
    "\n",
    "# Find location of star in model\n",
    "model_mean, model_median, model_std = sigma_clipped_stats(psf_model_sum, sigma=3.0) \n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=5.*model_std)\n",
    "model_sources = daofind(psf_model_sum-model_median) \n",
    "for col in model_sources.colnames:  \n",
    "    model_sources[col].info.format = '%.6g'  \n",
    "print(\"Sources detected in model:\")\n",
    "print(model_sources)  \n",
    "print()\n",
    "\n",
    "# (x,y) shift between model and data\n",
    "shiftx = data_sources['xcentroid'].data[0] - model_sources['xcentroid'].data[0]\n",
    "shifty = data_sources['ycentroid'].data[0] - model_sources['ycentroid'].data[0]\n",
    "print(\"Shift (x,y) = \", shiftx, shifty)\n",
    "print()\n",
    "\n",
    "# Shift model PSF using linear interpolation\n",
    "psf_model_aligned = scipy.ndimage.shift(psf_model_smoothed, (0.0, shifty, shiftx), order=1, \n",
    "                                        mode='constant', cval=0.0, prefilter=True)\n",
    "# Replace NaNs\n",
    "profile = np.nan_to_num(psf_model_aligned) \n",
    "\n",
    "# Sum over wavelength\n",
    "psf_model_aligned_sum = np.sum(psf_model_aligned, axis=0)\n",
    "\n",
    "# Scale factor for PSF subtraction\n",
    "psf_sum_min = np.amin(psf_model_aligned_sum)\n",
    "psf_sum_max = np.amax(psf_model_aligned_sum)\n",
    "scalefactor = np.amax(cube_sum) / psf_sum_max\n",
    "\n",
    "# Plots\n",
    "f, ([ax1, ax2, ax3], [ax4, ax5, ax6]) = plt.subplots(2, 3, figsize=(10, 10)) \n",
    "\n",
    "ax1.set_title(\"PSF slice sum\")\n",
    "ax1.imshow(psf_model_aligned_sum, norm=LogNorm())\n",
    "\n",
    "ax2.set_title(\"Science Data slice sum\")\n",
    "ax2.imshow(data_sum, norm=LogNorm()) \n",
    "\n",
    "ax3.set_title(\"Data / PSF Ratio\")\n",
    "ax3.imshow(data_sum / psf_model_aligned_sum, norm=LogNorm())\n",
    "\n",
    "ax4.set_title(\"PSF Model integrated flux\")\n",
    "ax4.plot(psf_model_fnusum)\n",
    "\n",
    "ax5.set_title(\"Data - PSF\")\n",
    "ax5.imshow(data_sum - scalefactor * psf_model_aligned_sum)\n",
    "\n",
    "im6 = ax6.imshow(np.log10(np.absolute(data_sum - scalefactor * psf_model_aligned_sum)))\n",
    "plt.colorbar(im6)\n",
    "ax6.set_title(\"log abs(Data - PSF)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure top row_: Comparison of smoothed, aligned WebbPSF (left) to IPS simulation (center). \n",
    "\n",
    "_Figure bottom row_: Integrated WebbPSF model flux (left) decreases with wavelength as PSF expands outside of the FOV. \n",
    "Differences (center, right) between the model PSF and IPS-simulated PSF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Extraction using WebbPSF Model\n",
    "Optimal extraction (Horne 1986, PASP, 98, 609) weights the flux contributions to a spectrum by their signal-to-noise ratio (SNR). Dividing the simulated data by the model PSF gives an estimate of the total flux density spectrum in each spaxel. A weighted average of these estimates over all spaxels yields the optimally extracted spectrum over the cube. In the faint source limit, where the noise is background-dominated, optimal extraction inside a 3-sigma radius can increase the effective exposure time by a factor of 1.69 (Horne et al. 1986). In the bright source limit, where the noise is dominated by the Poisson statistics of the source, optimal extraction is formally identical to a straight sum over spaxels for a perfect PSF model. \n",
    "\n",
    "We use the WebbPSF PSF model for this first attempt at optimal extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal extraction, using model profile weight and variance cube from the simulated data\n",
    "optimal_weight = profile ** 2 / data_var\n",
    "optimal_weight_norm = np.sum(optimal_weight, axis=(1, 2))\n",
    "spectrum_optimal = np.sum(profile * data_win / data_var, axis=(1, 2)) / optimal_weight_norm\n",
    "\n",
    "#Scale may be off if PSF doesn't match perfectly\n",
    "opt_scalefactor = np.median(np.nan_to_num(cone_sum / spectrum_optimal))  \n",
    "print(\"Scale Factor:\", opt_scalefactor)\n",
    "\n",
    "# Trim the extracted spectrum\n",
    "spec1d_optimal = Spectrum1D(flux=spectrum_optimal*u.MJy/u.sr, spectral_axis=wavelength)\n",
    "\n",
    "print(spec1d_optimal)\n",
    "\n",
    "# Plots\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(12, 6)) \n",
    "ax1.set_title(\"Optimal Extraction Comparison\")\n",
    "ax1.set_xlabel(\"Observed Wavelength (microns)\") \n",
    "ax1.set_ylabel(\"Flux Density\")\n",
    "ax1.set_ylim(0, 0.5)\n",
    "ax1.plot(wavelength, cone.flux.value, label=\"Conical Extraction\", alpha=0.5)\n",
    "ax1.plot(wavelength, spec1d_optimal.flux.value, label=\"Optimal\")\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimally extracted spectrum is less noisy than the aperture extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Extraction with (Simulated) Reference Star PSF\n",
    "A real (or simulated in this case) IFU observation of a star may be used for the PSF model rather than WebbPSF.  We employ a NIRSpec IPS simulated PSF, which matches our data better than the WebbPSF model.  We don't have to shift or smooth the PSF model because it was simulated at the same dither/detector position as the data. When using a real observation of a star for the PSF model, make sure it was observed at the same dither positions. It is also beneficial to reduce and extract both simulated datasets in the 'ifualign' detector coordinate system, so that we don't have to rotate the PSF star to match the science data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BoxPath = \"https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/IFU_optimal_extraction/\"\n",
    "fname_star = \"NRS00001-brightQSO-F100LP-G140H-01_1_491_SE_2020-08-26T12h15m00_s3d.fits\"\n",
    "filename_star = BoxPath + fname_star\n",
    "\n",
    "# Open and inspect the file\n",
    "with fits.open(fname_star, memmap=False) as hdulist:\n",
    "    sci_star = hdulist['SCI'].data\n",
    "    hdulist.info()\n",
    "    \n",
    "#Window the reference star data\n",
    "star_win = np.nan_to_num(np.array(sci_star)[good_wave[0]:good_wave[-1]+1, 5:-4, 3:])\n",
    "print(np.shape(star_win))\n",
    "\n",
    "#Sum over wavelength\n",
    "star_sum = np.sum(star_win, axis=0)\n",
    "\n",
    "# Reference star spectrum\n",
    "#star_fnusum = np.sum(star_win, axis=(1, 2))\n",
    "\n",
    "# Normalize PSF star profile to unity. (The flux will still be slightly off. Please see Developer's Note below.)\n",
    "star_spectrum = []\n",
    "star_norm = []\n",
    "for idx in range(len(wavelength)):\n",
    "    r_cone = r_pix * wavelength.value[idx] / wavelength.value[0]\n",
    "    aperture_cone = CircularAperture((center1_trim.x,center1_trim.y), r=r_cone)\n",
    "    phot_table = aperture_photometry(star_win[idx, :, :], aperture_cone)\n",
    "    star_phot = phot_table['aperture_sum'][0]\n",
    "    star_spectrum.append(star_phot)\n",
    "    star_norm.append(star_win[idx,:,:] / star_phot)\n",
    "    \n",
    "star_spec1d = Spectrum1D(flux=np.array(star_spectrum)*u.MJy/u.sr, spectral_axis=wavelength)\n",
    "print(star_spec1d)  \n",
    "    \n",
    "profile_star = np.array(star_norm)\n",
    "print(np.shape(profile_star))\n",
    "    \n",
    "# Sum over wavelength\n",
    "profile_star_sum = np.nan_to_num(np.sum(profile_star, axis=0))\n",
    "print(np.shape(profile_star_sum))\n",
    "\n",
    "# Scale factor for PSF subtraction\n",
    "profile_star_sum_max = np.amax(profile_star_sum)\n",
    "star_scalefactor = np.amax(data_sum) / profile_star_sum_max\n",
    "print(\"Data/Star scale factor: \", star_scalefactor)\n",
    "\n",
    "# Plots\n",
    "f, ([ax1, ax2, ax3], [ax4, ax5, ax6]) = plt.subplots(2, 3, figsize=(10, 10)) \n",
    "\n",
    "ax1.imshow(profile_star_sum, norm=LogNorm())\n",
    "ax1.set_title(\"PSF Star Slice sum\")\n",
    "\n",
    "ax2.imshow(data_sum, norm=LogNorm()) \n",
    "ax2.set_title(\"Science Data Slice sum\")\n",
    "\n",
    "ax3.imshow(np.abs(data_sum / profile_star_sum),norm=LogNorm())\n",
    "ax3.set_title(\"Data/Star_PSF Ratio\")\n",
    "\n",
    "star_model_ratio = profile_star_sum / psf_model_sum\n",
    "ax4.imshow(star_model_ratio, norm=LogNorm())\n",
    "ax4.set_title(\"Star PSF/WebbPSF\")\n",
    "\n",
    "ax5.imshow(data_sum - star_scalefactor * profile_star_sum)\n",
    "ax5.set_title(\"Data - Star PSF\")\n",
    "\n",
    "ax6.imshow(np.log10(np.absolute(data_sum - star_scalefactor * profile_star_sum)))\n",
    "ax6.set_title(\"log abs(Data - Star PSF)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure top row_: Comparison of PSF star and science data. Bottom left: ratio of PSF star to WebbPSF model shows \n",
    "significant differences that can affect the quality of the optimal extraction.  Bottom right:\n",
    "Difference of PSF star from science data shows they are well matched, with a scale factor of 0.175. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Note:* It would be good to renormalize the PSF profile to account for the fraction of flux lost outside of the detector. Otherwise the extracted flux will be low by a factor of roughly 0.972 to 0.980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal extraction, using model profile weight and variance cube from the simulated data\n",
    "optimal_weight = profile_star**2 / data_var\n",
    "optimal_weight_norm = np.sum(optimal_weight, axis=(1, 2))\n",
    "spectrum_optimal_star = np.sum(profile_star * data_win / data_var, axis=(1, 2)) / optimal_weight_norm\n",
    "\n",
    "# Create Spectrum1D object\n",
    "spec1d_optimal_star = Spectrum1D(flux=spectrum_optimal_star*u.MJy/u.sr, spectral_axis=wavelength)\n",
    "print(spec1d_optimal_star)\n",
    "\n",
    "# Plots\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(12, 6)) \n",
    "ax1.set_title(\"Optimal Extraction Comparison\")\n",
    "ax1.set_xlabel(\"Observed Wavelength (microns)\") \n",
    "ax1.set_ylabel(\"Flux Density\")\n",
    "ax1.set_ylim(0, 0.5)\n",
    "\n",
    "ax1.plot(wavelength, cone.flux.value, label=\"Conical Extraction\", alpha=0.5)\n",
    "ax1.plot(wavelength, spec1d_optimal.flux.value, label=\"Optimal with WebbPSF model\", alpha=0.5)\n",
    "ax1.plot(wavelength, spec1d_optimal_star.flux.value, label=\"Optimal with ref. star\")\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal extraction with the perfectly matched PSF star is less noisy than that achieved with WebbPSF.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook created by Patrick Ogle and James Davies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
